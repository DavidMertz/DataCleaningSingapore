{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a10f491-4114-4ab9-953a-9f8d6e0d8cce",
   "metadata": {},
   "source": [
    "# Tabulat Data Formats: Tidying Up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b80717-d88d-4cb6-9a4d-c3885d001d41",
   "metadata": {},
   "source": [
    "Check the Python version and load miscellaneous utility functions and classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9482bef9-ca8e-4f11-8762-b2e34dd43d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.10.4 | packaged by conda-forge | (main, Mar 24 2022, 17:38:57) [GCC 10.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e9287d5-da81-4040-9689-767de3a0cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7b04d9-e664-41ea-8a6f-c67f58c7a95e",
   "metadata": {},
   "source": [
    "## Types of Grime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8faca1-34ae-48ff-8f84-0a613da353c4",
   "metadata": {},
   "source": [
    "There are roughly two families of problems we find in data sets.  Not every problem neatly divides into these families, or at least it is not always evident which side something falls on without knowing the root cause.  But in a general way we can think of structural problems in the formatting of data versus content problems in the actual values recorded.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e9d52d-c91b-4caf-a97c-fb2bf42fe78c",
   "metadata": {},
   "source": [
    "On the structural branch a format used to encode a data set might simply \"put values in the wrong place\" in one way or another.  On the content side, the data format itself is correct, but implausible or wrong values have snuck in via flawed instruments, transcription errors, numeric overflows, or through other pitfalls of the recording process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80be95f-2a1b-40f0-84e6-d8ca93c3e35f",
   "metadata": {},
   "source": [
    "In the case of structural problems, we almost always need manual remediation of the data.  Exactly where the bytes that make up the data go wrong can vary enormously, and usually does not follow a pattern that lends itself to a single high-level description.  Often we have a somewhat easier time with the content problems, but at the same time they are more likely to be irremediable even with manual work.  Consider this small comma-separated value (CSV) data source, describing a 6th grade class:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013863ab-2931-449f-9b7e-7199e1bac5d4",
   "metadata": {},
   "source": [
    "```\n",
    "Student#,Last Name,First Name,Favorite Color,Age\n",
    "1,Johnson,Mia,periwinkle,12\n",
    "2,Lopez,Liam,blue,green,13\n",
    "3,Lee,Isabella,,11\n",
    "4,Fisher,Mason,gray,-1\n",
    "5,Gupta,Olivia,9,102\n",
    "6,,Robinson,,Sophia,,blue,,12\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7916acde-1994-4b3c-941f-6707561e3cbf",
   "metadata": {},
   "source": [
    "In a friendly way, we have a header line that indicates reasonable field names and provides a hint as to the meaning of each column.  Programmatically, we may not wish to work with the punctuation marks and spaces inside some field names, but that is a matter of tool convenience that we can address with the APIs (*application programming interfaces*; the functions and methods of a library) that data processing tools give us (perhaps by renaming them)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa82d3a-1880-4ad5-a214-4bcecaef2b38",
   "metadata": {},
   "source": [
    "Let us think about each record in turn.  \n",
    "* Mia Johnson, student 1, seems to have a problem-free record.  Her row has five values separated by four commas, and each data value meets our intuitive expectations about the data type and value domain.  The problems start hereafter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cddb9a-5bde-436f-b46e-c79f4f0d09dc",
   "metadata": {},
   "source": [
    "* Liam Lopez has too many fields in his row.  However, both columns 4 and 5 seem clearly to be in the lexicon of color names.  Perhaps a duplicate entry occurred or the compound color \"blue-green\" was intended.  Structurally the row has issues, but several plausible remediations suggest themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c341a5-0184-4662-9760-2496cdabe0e2",
   "metadata": {},
   "source": [
    "* Isabella Lee is perhaps no problem at all.  One of her fields is empty, meaning no favorite color is available.  But structurally, this row is perfectly fine for CSV format.  We will need to use some domain or problem knowledge to decide how to handle the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65583c0-e169-422f-a880-2ba7e5f121f2",
   "metadata": {},
   "source": [
    "* Mason Fisher is perhaps similar to Isabella.  The recorded age of -1 makes no sense in the nature of \"age\" as a data field, at least as we usually understand it (but maybe the encoding intends something different).  On the other hand, -1 is one of several placeholder values used very commonly to represent missing data.  We need to know our specific problem to know whether we can process the data with a missing age, but many times we can handle that.  However, we still need to be careful not to treat the -1 as a plain value; for example, the mean, minimum, or standard deviation of ages might be thrown off by that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ea7a7d-45ac-4d62-9912-1cee3bf2e9d0",
   "metadata": {},
   "source": [
    "* Olivia Gupta starts to present a trickier problem.  Structurally her row looks perfect.  But '9' is probably not a string in our lexicon of color names.  And under our understanding of the data concerning a 6th grade class, we don't expect 102 year old students to be in it.  To solve this row, we really need to know more about the collection procedure and the intention of the data.  Perhaps a separate mapping of numbers to colors exists somewhere.  Perhaps an age of 12 was mistranscribed as 102; but also perhaps a 102 year old serves as a teaching assistant in this class and not only students are recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cfb8c5-600b-43f0-b3c3-6a58e2840d60",
   "metadata": {},
   "source": [
    "* Sophia Robinson returns us to what looks like an obvious structural error.  The row, upon visual inspection, contains perfectly good and plausible values, but they are separated by duplicate commas.  Somehow, persumably, a mechanical error resulted in the line being formatted wrongly.  However, most high-level tools are likely to choke on the row in an uninformative way, and we will probably need to remediate the issue more manually."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18579345-35e4-4783-996e-a102c196e911",
   "metadata": {},
   "source": [
    "We have a pretty good idea what to do with these six rows of data, and even re-entering them from scratch would not be difficult.  If we had a million rows instead, the difficulty would grow greatly, and would require considerable effort before we arrived at usable data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f1cbaf-c549-4d53-89a6-cb5e6805d7a6",
   "metadata": {},
   "source": [
    "## Nomenclature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1219be-4355-4818-8efa-0bdb56efe088",
   "metadata": {},
   "source": [
    "In this course I will use the terms *feature*, *field*, *measurement*, *column*, and occasionally *variable* more-or-less interchangeably.  Likewise, the terms *row*, *record*, *observation*, and *sample* are also near synonyms.  *Tuple* is used for the same concept when discussing databases (especially academically). In different academic or business fields, different ones of these terms are more prominent; and likewise different software tools choose among these. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd1b3e-2d2f-407d-ad0a-9f9a6fd1ffdf",
   "metadata": {},
   "source": [
    "Conceptually, most data can be thought of as a number of occasions on which we measure various attributes of a common underlying *thing*.  In most tools, it is usually convenient to put these observations/samples each in a row; and correspondingly to store each of the measurements/features/fields pertaining to that thing in a column containing corresponding data for other comparable *things*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96db05d-2db9-447a-87a0-4e940fdd21f4",
   "metadata": {},
   "source": [
    "## Tidy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b71c04b-1ebc-47b1-a58f-d1ca9dc77f2c",
   "metadata": {},
   "source": [
    "Tidy data carefully separates variables (the columns of a table; also called features or fields) from observations (the rows of a table; also called samples).  At the intersection of these two, we find values, one data item (datum) in each cell.  Unfortunately, the data we encounter is often not arranged in this useful way, and it requires *normalization*.  In particular, what are really values are often represented either as columns or as rows instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9e31c46-3e8b-44d3-90a4-ae8b0cc5ab8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/students-scores.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m students \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/students-scores.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m students\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning-data-singapore/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning-data-singapore/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning-data-singapore/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning-data-singapore/lib/python3.10/site-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning-data-singapore/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/cleaning-data-singapore/lib/python3.10/site-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/students-scores.csv'"
     ]
    }
   ],
   "source": [
    "students = pd.read_csv('data/students-scores.csv')\n",
    "students"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d0f2ae-ebf2-4044-b8d6-211f8ae11da1",
   "metadata": {},
   "source": [
    "This view of the data is easy for humans to read.  We can see trends in the scores each student received over several years of education.  Moreover, this format might lend itself to useful visualizations fairly easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87487c7e-14fa-4694-8b2d-4fe3a055bfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic conversion of letter grades to numbers\n",
    "def num_score(x):\n",
    "    to_num = {'A+': 4.3, 'A': 4, 'A-': 3.7,\n",
    "              'B+': 3.3, 'B': 3, 'B-': 2.7,\n",
    "              'C+': 2.3, 'C': 2, 'C-': 1.7}\n",
    "    return x.map(lambda x: to_num.get(x, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed68a28-6816-4adc-9174-5c84f352d9e7",
   "metadata": {},
   "source": [
    "This next cell uses a \"fluent\" programming style that may look unfamiliar to some Python programmers.  I discuss this style in the section below on data frames.  The fluent style is used in many data science tools and languages. For example, this is typical Pandas code that plots the students' scores by year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9ad90e8-00d9-42e0-b2ad-9620bb05eff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'students' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m (\u001b[43mstudents\u001b[49m\n\u001b[1;32m      2\u001b[0m      \u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast Name\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m      \u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFirst Name\u001b[39m\u001b[38;5;124m'\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      4\u001b[0m      \u001b[38;5;241m.\u001b[39mapply(num_score)\n\u001b[1;32m      5\u001b[0m      \u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m      6\u001b[0m      \u001b[38;5;241m.\u001b[39mplot(title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent score by year\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m      \u001b[38;5;241m.\u001b[39mlegend(bbox_to_anchor\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m.75\u001b[39m))\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39msavefig(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg/(Ch01)Student score by year\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'students' is not defined"
     ]
    }
   ],
   "source": [
    "(students\n",
    "     .set_index('Last Name')\n",
    "     .drop('First Name', axis=1)\n",
    "     .apply(num_score)\n",
    "     .T\n",
    "     .plot(title=\"Student score by year\")\n",
    "     .legend(bbox_to_anchor=(1, .75))\n",
    ")\n",
    "plt.savefig(\"img/(Ch01)Student score by year\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121dbaf-e4e2-46a2-8607-e937b868cf0a",
   "metadata": {},
   "source": [
    "This data layout exposes its limitations once the class advances to 7th grade, or if we were to obtain 3rd grade information.  To accommodate such additional data, we would need to change the number and position of columns, not simply add additional rows.  It is natural to make new observations or identify new samples (rows), but usually awkward to change the underlying variables (columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d15dd-546a-47be-b3a2-75f0be2a3cfe",
   "metadata": {},
   "source": [
    "The particular class level (e.g. 4th grade) that a letter grade pertains to is, at heart, a value not a variable.  Another way to think of this is in terms of independent variables versus dependent variables.  Or in machine learning terms, features versus target.  In some way, the class level might correlate with or influence the resulting letter grade; perhaps the teachers at the different levels have different biases, or children of a certain age lose or gain interest in schoolwork, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea34917c-fa39-473f-b6c9-e059eee05a99",
   "metadata": {},
   "source": [
    "For most analytic purposes, this data would be more useful if we make it tidy (normalized) before further processing.  In Pandas, the `DataFrame.melt()` method can perform this tidying.  We pin some of the columns as `id_vars`, and we set a name for the combined columns as a variable and the letter grade as a single new column.  This Pandas method is slightly magical, and takes some practice to get used to.  The key thing is that it preserves data, simply moving it between column labels and data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61a863fa-4d9a-4e39-8498-1cd73ae5f400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Level</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Mia</th>\n",
       "      <th>Johnson</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Liam</th>\n",
       "      <th>Lopez</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isabella</th>\n",
       "      <th>Lee</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mason</th>\n",
       "      <th>Fisher</th>\n",
       "      <th>4th Grade</th>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Isabella</th>\n",
       "      <th>Lee</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>B-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mason</th>\n",
       "      <th>Fisher</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>C+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Olivia</th>\n",
       "      <th>Gupta</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sophia</th>\n",
       "      <th>Robinson</th>\n",
       "      <th>6th Grade</th>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Score\n",
       "First Name Last Name Level          \n",
       "Mia        Johnson   4th Grade     A\n",
       "Liam       Lopez     4th Grade     B\n",
       "Isabella   Lee       4th Grade     C\n",
       "Mason      Fisher    4th Grade     B\n",
       "...                              ...\n",
       "Isabella   Lee       6th Grade    B-\n",
       "Mason      Fisher    6th Grade    C+\n",
       "Olivia     Gupta     6th Grade     A\n",
       "Sophia     Robinson  6th Grade     A\n",
       "\n",
       "[18 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "students.melt(\n",
    "    id_vars=[\"Last Name\", \"First Name\"], \n",
    "    var_name=\"Level\",\n",
    "    value_name=\"Score\"\n",
    ").set_index(['First Name', 'Last Name', 'Level'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbca105b-6a42-4e26-86ec-1caaa0c28c0d",
   "metadata": {},
   "source": [
    "In the R Tidyverse, the procedure is similar.  Do not worry about the extra Jupyter magic `%%capture`, this simply quiets extra informational messages sent to STDERR that would distract from the printed book.  A **tibble** that we see here is simply a kind of data frame that is preferred in the Tidyverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9fbcee14-8159-4714-8bec-5e060658c525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[36m──\u001b[39m \u001b[1m\u001b[1mColumn specification\u001b[1m\u001b[22m \u001b[36m──────────────────────────────────────────────────────────────────\u001b[39m\n",
      "cols(\n",
      "  `Last Name` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `First Name` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `4th Grade` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `5th Grade` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `6th Grade` = \u001b[31mcol_character()\u001b[39m\n",
      ")\n",
      "\n",
      "\u001b[90m# A tibble: 6 x 5\u001b[39m\n",
      "  `Last Name` `First Name` `4th Grade` `5th Grade` `6th Grade`\n",
      "  \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m      \n",
      "\u001b[90m1\u001b[39m Johnson     Mia          A           B+          A-         \n",
      "\u001b[90m2\u001b[39m Lopez       Liam         B           B           A+         \n",
      "\u001b[90m3\u001b[39m Lee         Isabella     C           C-          B-         \n",
      "\u001b[90m4\u001b[39m Fisher      Mason        B           B-          C+         \n",
      "\u001b[90m5\u001b[39m Gupta       Olivia       B           A+          A          \n",
      "\u001b[90m6\u001b[39m Robinson    Sophia       A+          B-          A          \n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "library('tidyverse')\n",
    "\n",
    "studentsR <- read_csv('data/students-scores.csv')\n",
    "studentsR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab958f-e740-483d-9cf8-30f5a4ff1c0b",
   "metadata": {},
   "source": [
    "Within the Tidyverse, specifically within the **tidyr** package, there is a function `pivot_longer()` that is similar to Pandas' `.melt()`.  The aggregation names and values have parameters spelled `names_to` and `values_to`, but the operation is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57f2764-0060-4284-a2af-672fc498ffd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[36m──\u001b[39m \u001b[1m\u001b[1mColumn specification\u001b[1m\u001b[22m \u001b[36m──────────────────────────────────────────────────────────────────\u001b[39m\n",
      "cols(\n",
      "  `Last Name` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `First Name` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `4th Grade` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `5th Grade` = \u001b[31mcol_character()\u001b[39m,\n",
      "  `6th Grade` = \u001b[31mcol_character()\u001b[39m\n",
      ")\n",
      "\n",
      "\u001b[90m# A tibble: 18 x 4\u001b[39m\n",
      "   `Last Name` `First Name` Level     Score\n",
      "   \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m       \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m        \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m     \u001b[3m\u001b[90m<chr>\u001b[39m\u001b[23m\n",
      "\u001b[90m 1\u001b[39m Johnson     Mia          4th Grade A    \n",
      "\u001b[90m 2\u001b[39m Johnson     Mia          5th Grade B+   \n",
      "\u001b[90m 3\u001b[39m Johnson     Mia          6th Grade A-   \n",
      "\u001b[90m 4\u001b[39m Lopez       Liam         4th Grade B    \n",
      "\u001b[90m 5\u001b[39m Lopez       Liam         5th Grade B    \n",
      "\u001b[90m 6\u001b[39m Lopez       Liam         6th Grade A+   \n",
      "\u001b[90m 7\u001b[39m Lee         Isabella     4th Grade C    \n",
      "\u001b[90m 8\u001b[39m Lee         Isabella     5th Grade C-   \n",
      "\u001b[90m 9\u001b[39m Lee         Isabella     6th Grade B-   \n",
      "\u001b[90m10\u001b[39m Fisher      Mason        4th Grade B    \n",
      "\u001b[90m11\u001b[39m Fisher      Mason        5th Grade B-   \n",
      "\u001b[90m12\u001b[39m Fisher      Mason        6th Grade C+   \n",
      "\u001b[90m13\u001b[39m Gupta       Olivia       4th Grade B    \n",
      "\u001b[90m14\u001b[39m Gupta       Olivia       5th Grade A+   \n",
      "\u001b[90m15\u001b[39m Gupta       Olivia       6th Grade A    \n",
      "\u001b[90m16\u001b[39m Robinson    Sophia       4th Grade A+   \n",
      "\u001b[90m17\u001b[39m Robinson    Sophia       5th Grade B-   \n",
      "\u001b[90m18\u001b[39m Robinson    Sophia       6th Grade A    \n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout err\n",
    "%%R\n",
    "studentsR <- read_csv('data/students-scores.csv')\n",
    "studentsR %>% \n",
    "  pivot_longer(c(`4th Grade`, `5th Grade`, `6th Grade`), \n",
    "               names_to = \"Level\", \n",
    "               values_to = \"Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f5443-e1ed-41a2-a758-8b1565be4488",
   "metadata": {},
   "source": [
    "The simple example above gives you a first feel for tidying tabular data.  To reverse the tidying operation that moves variables (columns) to values (rows), the `pivot_wider()` function in tidyr can be used.  In Pandas there are several related methods on DataFrames, including `.pivot()`, `.pivot_table()`, and `.groupby()` combined with `.unstack()`, which can create columns from rows (and do many other things too)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c3215-a2cd-41e2-bcd8-3ba4e72d4548",
   "metadata": {},
   "source": [
    "Having looked at the idea of tidyness as a general goal for tabular, let us being looking at specific data formats, beginning with comma-separated values and fixed-width files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc0049f-d894-4b03-8603-a3b6c17c6919",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
